# Week of November 15th - 19th

1) We acquired two datasets that we could eventually use for our data visualization. These datasets were within the state of Illinois and characterized by datapoints that associated a quantifable density of some charactersitic (such as population) with a physical location that could be consistently converted into a precise geographical location.
   
2) Using a geocoding script as well as other basic scripts that modified written data to exlcude things such as commas, we performed basic data cleaning and processed the datasets into CSV files that our algorithims could parse and use. The geocoding script was crucial because it converted the name of towns and other locations into numerical latitude-longitude values that could be associated with a single point on a coordinate plane.
   
3) We thought more clearly about the logistics for our project including drafting preliminary documentation for all the functions we were planning on using. This included thinking about the logistics of how we were going to represent the data visually on our map png in terms of pixels. Ultimately we decided on centering the visualization around the idea of treating each individual pixel as a cell and associating a "weight" with that cell that would correlate linearly with a hue on a color gradient that we would decide on at a later date. The weight would be built as summation of contributions of all the datapoints within a certain radius of the cell, each contribution being linearly proportional to population density or another quantifiable metric and inversely exponentialy proportional to distance from the cell to the datapoint. We ultimately planned to use a KDTree and an Image Traversal for this first part of the project. 
   
4) We drafted a revised proposal that was more detailed than our original one based upon the preliminary documentation that we drafted. We also included Prim's Algorithim to fulfill the graph algorithim requirement for the project.

